1. 我会对解决问题的过程记录日志，操作系统，编译器，数据库
2. 在解决完问题之后我会不时地回顾日志
3. 编译器会根据现代的乱序处理器做一些优化，比如循环展开+多个累积变量(或者重新结合变换)，使用条件传送。
4. 编写编译器的难点
    a. 词法分析很考验逻辑处理能力
    b. 语法分析则要处理所有情况，考验你的抽象能力
    c. 生成中间代码则考验对汇编的理解，以及代码能力(因为要处理一棵树)
    d. 优化阶段考验你对底层处理器的理解和代码能力

难点：
    1. 词法分析的运算符很麻烦。
    2. 此法分析要考虑所有情况，这个会重新检查。
    3. 语法分析要考虑到运算符的优先级，以及语法树的上下顺序。
    4. 语法分析需要详细的分析和思考，以及代码能力和抽象能力。

疑问：
    1. 为什么 parser_reorder_expression(&exp_node); 要用双重指针呢？
    2. 什么情况下表达式的左右节点都是表达式节点？对于这样节点的优先级又该怎么处理呢？
    3. 对于E(E(1 + 2) * 3)的优先级怎么处理，原序列是 1 + 2 * 3
    4. parse_next()函数究竟是干什么的？
    5. 没体现出空白符的分割能力(空格, 换行符, 制表符)
    6. 重新检查的时候留意对于公共方法，指针是否都检查空指针了
    7. 重新检查的时候一定要很多情况都测试一下，首先测试词法分析是否合法、齐全。然后测试语法分析的表达式和关键字前半部分。

日志：
词法分析：
    1. 对单引号和注释的处理
    2. 对16进制数的处理，这个要考虑若干情况，比如 "000x" "123x" "0 x" "0xyz"
    3. 对2进制数的处理，这里和原作者不太一样，我把 0b123 -> 1 23，原作者会直接报错
    4. 添加了对括号表达式的处理，nextc时放进buffer，token_create()会检测是否在表达式里，若是则token的指针指向它，目的未知
    5. 之前的词法分析是基于文件的，现在添加了一个基于字符串的lex函数，原作者的pushc有bug，已修改
    6. 给number加了一个类型，识别诸如 12L 123.0f 这种，但是不全，没有 long long 和 double，number 这个是有难度的。
    7. 从抽象意义上来说，lex_process只是生成token序列的，生成完之后还是要交给compile_process，但是词法分析就这样结束了吗？
        感觉这个此法分析还不完美，比如那个表达式缓冲区是干什么的，number的类型以及浮点数的问题还没解决。
    8. 新建一个”解析器“和一个新的结构node，这个node是干什么的，感觉和token很像。node中的信息可以指明该node属于哪个body,
        属于哪个函数。这个应该是要处理之前的括号表达式的问题，而且node还能识别当前的结构，比如if, while等等。这是语法分析吗？
    9. 新增了语法分析的框架和启动，其中 node_vec 和 node_tree_vec 存储的是 node 的指针。
    10. 创建了一些node相关的方法，他创建了node_vector和node_vector_root，前者存语法树的节点，后者存语法树的根节点。而且这
        个vector存的是node指针，因此一些细节上可能会不同，比如 ptr = *(struct node**)vector_back(node_vector)
        vector_back 返回指向最后一个元素的指针，如果存的元素也是指针，我们可以把返回值看成一个双重指针，所以 *返回值就是指向
        实际node的指针，这正是我们想要的。(不如说这个返回值本来就是struct node** 类型的)
    11. 目前做的事就是忽略换行，注释和反斜。然后对于数字，变量还有字符串token制作node，制作好的node被放入node_vec，然后将最新
        的node，也就是node_vec的最后一个值存进node_tree_vec，目前还不清楚node_vec和node_tree_vec的区别，但我估计node_t
        ree_vec是用来存储根节点的？
    12. 新增加了表达式node，将表达式序列看成一颗中序遍历的一棵树，将运算符看成是根节点，每次遇到运算符，就将左边的node当成左孩子，
        计算右边序列的语法树，并作为自己的右孩子。还有函数来检查一个node是否是表达式node，说明还有很多其他类型的node。指导了node
        _vec 和 node_tree_vec 的含义，node_vec 只是一个临时node数组，而 node_tree_vec 才是我们真正想要的，是语法树根节点的
        集合。
    13. 创建了一个用于表示优先级的结构，它把一类运算符放到一起，然后标注他们的优先级顺序，比如 a + b, 我肯定是先算出a的值，再算出
        b 的值，然后将它们相加，这就是从左到右。如果是 a = b，那么我肯定是先算出b的值，然后赋给a，这就是从右到左。再比如 a?b:c，
        这种条件转移语句，我肯定是先算出b和c，然后在根据a的值来返回。
    14. 之前对优先级集合的理解有误，他操作的不是语法树的左右，而是上下，因为下层的节点总是比上层的节点先算出来，而且他是越靠前的集合
        优先级越高。然后如果出现优先级有误，那么就会对语法树做一个旋转操作。但是有两个疑问。详见疑问2,3
    15. 新增了一个node检查，发现了两个bug，详见bug3，4。还有就是我对表达式的处理过程还有优先级的处理过程理解错了，我之前还怀疑他的
        代码，看来是我错了。首先他的表达式处理是递归的，即先处理左节点，再处理右子树，然后将左节点和右子树连在操作符上。这样每新构造
        出的语法树都是左边是节点，然后右边是一个表达式或者节点。对于生成的一颗新子树，都会对整棵树进行优先级调整，如果一个节点调整了，
        那么它的两个孩子就会被影响，也要对他的孩子进行调整，可以证明这个从上往下的调整是没有前效性的，因为左边的是调整过的，右边的是
        在前几轮就调整过是没有矛盾的，也就是说唯一会冲突的就是左孩子和左孩子的右孩子。
        优先级调整的本质就是将左边的高优先级运算符下沉到合适的高度。
    16. 新增了变量的node，在表达式中，变量和数字的地位是相同的。
    17. 新增了识别类型定义的函数，类型定义就是 const, static 这些，类型定义可以有很多个，每个定义都代表一个状态，最后这些状态都
        会赋给变量，相当于变量的一个buff。识别类型定义只是识别关键字的一部分，后面还有很长的路。
    18. 创建了识别类型的函数，首先提取出类型token，最多有两个。然后检查第一个token是不是 union 或者 struct, 如果是则要提取出
        类型名，如果没有类型名要创建一个类型名，提取类型名后赋给第一个token。最后在提取指针的深度。这里有三种情况，声明，定义，和
        初始化，总之可以预见语法分析是一个困难且工作量很大的项目，需要进行详细的分析和思考，同时对原作者代码的理解。这是一个长期项
        目，因此暂时挂起，先做内核项目，做完后在来做这个，总之编译器这个项目我是一定要写出来的。
    
日志简介： 
    1. 新增表达式node，将token序列看作语法树的中序序列
    2. 创建了表达语法树左右孩子的优先级集合，越靠前的集合优先级越大。
    3. 写了比较优先级的函数，写了递归的处理一个表达式并将其做成语法树，并且根据优先级进行旋转。
    4. 之前理解错误，他是 左节点-操作符-右子树 的一个递归，并且对每个新创建的树进行优先级调整，本质是将左边的高优先级运算符下沉到
        合适的高度。做了测试工作，找到了bug，修正了自己的理解错误。
    5. 新增了变量的node。
    6. 新增了处理类型定义的函数。
    7. 创建了识别类型的函数，包括对 union 和 struct 的识别以及指针深度的识别。